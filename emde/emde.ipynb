{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMDE\n",
    "Experiments with Efficient Manifold Density Estimation - based on the paper\n",
    "https://arxiv.org/abs/2006.01894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import scipy.sparse as ssp\n",
    "\n",
    "\n",
    "def EMDE_transform(K, N, item_vectors):\n",
    "    \"\"\"takes a and array of embedding vectors and \n",
    "    returns a sparse array of their sketches\n",
    "    \"\"\"\n",
    "    n_items, d = item_vectors.shape\n",
    "    shallow_sketches = []\n",
    "    for _ in range(N):\n",
    "        # first chose K vectors at random - these are the normal vectors to the K hyperplanes\n",
    "        random_vectors = np.random.normal(size=(K, d))\n",
    "        \n",
    "        # for every hyperplane choose one of the items at random\n",
    "        # we will choose the offset for the hyperplane so that it passes\n",
    "        # through the selected item (or rather the item's vector)\n",
    "        random_inds = np.random.randint(n_items, size=K)\n",
    "        \n",
    "        # scalar product of every item with the random vectors\n",
    "        scalar_products = random_vectors.dot(item_vectors.T)\n",
    "        offsets = scalar_products[range(K), random_inds]\n",
    "\n",
    "        # for every point for every plane determine \n",
    "        # on which side of the plane does the point lie\n",
    "        # the result is a boolean array of size (n_items, K)\n",
    "        bits = (scalar_products > offsets.reshape([K, 1])).T\n",
    "\n",
    "        # for every item encode the sequence of booleans as an integer using binary\n",
    "        # the result is an integer array of length n_items\n",
    "        bucket_nums = (bits * (2**np.arange(K))).sum(axis=1)\n",
    "\n",
    "        # one-hot-encoding on bucket numbers\n",
    "        sketch = CountVectorizer(analyzer=lambda x: x).fit_transform(bucket_nums.reshape(n_items, 1))\n",
    "        shallow_sketches.append(sketch)\n",
    "\n",
    "    return ssp.hstack(shallow_sketches)\n",
    "    \n",
    "class EMDEVectorizer(object):\n",
    "    \"\"\"A drop-in replacement for CountVectorizer and TfidfVectorizer\n",
    "    - based on EMDE\n",
    "    \n",
    "    The dimensionality of the transformed vectors is not deterministic\n",
    "    and is at most N * 2**K - but typically much smaller. \n",
    "    That is because buckets with no points in them get dropped by CountVectorizer\n",
    "    \"\"\"\n",
    "    def __init__(self, K, N, item2vec, tfidf=False):\n",
    "        items = list(item2vec.keys())\n",
    "        item_vectors = np.vstack(list(item2vec.values()))\n",
    "        \n",
    "        self.emde_embeddings = EMDE_transform(K, N, item_vectors)\n",
    "        if tfidf:\n",
    "            self.vectorizer = TfidfVectorizer(analyzer=lambda x: x, vocabulary=items)\n",
    "        else:\n",
    "            self.vectorizer = CountVectorizer(analyzer=lambda x: x, vocabulary=items)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # this is only necessary for tfidf=True, otherwise it does nothing\n",
    "        self.vectorizer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.vectorizer.transform(X).dot(self.emde_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 1],\n",
       "        [3, 0, 0, 0, 3, 0],\n",
       "        [1, 2, 1, 1, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item2vec = {\n",
    "    'chorizo': np.array([0.2, -0.4, 0.15]),\n",
    "    'banana': np.array([0.7, -1.2, 2.56]),\n",
    "    'sourdough': np.array([0.9, 0.1, 0.04])\n",
    "}\n",
    "\n",
    "user_baskets = [\n",
    "    ['chorizo', 'banana'],\n",
    "    ['sourdough'],\n",
    "    ['banana', 'banana', 'banana'],\n",
    "    ['banana', 'chorizo', 'sourdough', 'sourdough']\n",
    "]\n",
    "\n",
    "emde = EMDEVectorizer(K=3, N=2, item2vec=item2vec)\n",
    "\n",
    "users_embedded = emde.transform(user_baskets)\n",
    "users_embedded.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1.        , 1.        , 1.        , 1.        ],\n",
       "        [0.        , 1.        , 0.        , 1.        ],\n",
       "        [0.        , 1.        , 1.        , 0.        ],\n",
       "        [0.33333333, 1.        , 0.33333333, 1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "normalize(users_embedded, 'max').todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-embedding vectorizer\n",
    "Let's include a vectorizer that takes arithmetic mean of embedding vectors as a simple baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, item2vec, vocabulary=None, tfidf=True):\n",
    "        self.vocab = vocabulary or item2vec.keys()\n",
    "        self.item_vectors = np.vstack([item2vec[item] for item in self.vocab])\n",
    "        if tfidf:\n",
    "            self.vectorizer = TfidfVectorizer(analyzer=lambda x: x, vocabulary=self.vocab)\n",
    "        else:\n",
    "            self.vectorizer = CountVectorizer(analyzer=lambda x: x, vocabulary=self.vocab)\n",
    "            \n",
    "    def fit(self, X, y=None):\n",
    "        self.vectorizer.fit(X)\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        item_counts = self.vectorizer.transform(X)\n",
    "        counts_normed = normalize(item_counts, norm='l1')\n",
    "        return counts_normed.dot(self.item_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks\n",
    "Download some data to test on. We will use a text classifation benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-09-28 21:21:51--  http://www.cs.umb.edu/~smimarog/textmining/datasets/r8-train-no-stop.txt\n",
      "Resolving www.cs.umb.edu (www.cs.umb.edu)... 158.121.106.224\n",
      "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.cs.umb.edu:443/~smimarog/textmining/datasets/r8-train-no-stop.txt [following]\n",
      "--2020-09-28 21:21:52--  https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-train-no-stop.txt\n",
      "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2537362 (2.4M) [text/plain]\n",
      "Saving to: ‘r8-train-no-stop.txt.1’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  2%  584K 4s\n",
      "    50K .......... .......... .......... .......... ..........  4% 1.23M 3s\n",
      "   100K .......... .......... .......... .......... ..........  6% 11.8M 2s\n",
      "   150K .......... .......... .......... .......... ..........  8% 1.38M 2s\n",
      "   200K .......... .......... .......... .......... .......... 10% 12.3M 2s\n",
      "   250K .......... .......... .......... .......... .......... 12% 11.4M 1s\n",
      "   300K .......... .......... .......... .......... .......... 14% 11.4M 1s\n",
      "   350K .......... .......... .......... .......... .......... 16% 11.9M 1s\n",
      "   400K .......... .......... .......... .......... .......... 18% 1.79M 1s\n",
      "   450K .......... .......... .......... .......... .......... 20% 11.3M 1s\n",
      "   500K .......... .......... .......... .......... .......... 22% 11.8M 1s\n",
      "   550K .......... .......... .......... .......... .......... 24% 11.6M 1s\n",
      "   600K .......... .......... .......... .......... .......... 26% 11.6M 1s\n",
      "   650K .......... .......... .......... .......... .......... 28% 11.4M 1s\n",
      "   700K .......... .......... .......... .......... .......... 30% 11.6M 1s\n",
      "   750K .......... .......... .......... .......... .......... 32% 11.9M 1s\n",
      "   800K .......... .......... .......... .......... .......... 34%  898K 1s\n",
      "   850K .......... .......... .......... .......... .......... 36%  253M 1s\n",
      "   900K .......... .......... .......... .......... .......... 38%  265M 0s\n",
      "   950K .......... .......... .......... .......... .......... 40%  254M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 42%  248M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 44%  289M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 46%  289M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 48%  269M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 50% 1.71M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 52% 14.5M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 54%  263M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 56%  286M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 58%  189M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 60%  287M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 62%  283M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 64%  284M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 66%  249M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 68%  273M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 70% 93.7M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 72% 11.2M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 74% 11.9M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 76% 11.5M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 78% 11.3M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 80% 12.1M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 82% 8.89M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 84% 10.7M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 86% 11.3M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 88% 10.3M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 90% 11.5M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 92% 11.5M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 94% 11.7M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 96% 11.8M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 98% 8.77M 0s\n",
      "  2450K .......... .......... .......                         100% 27.7M=0.4s\n",
      "\n",
      "2020-09-28 21:21:52 (6.16 MB/s) - ‘r8-train-no-stop.txt.1’ saved [2537362/2537362]\n",
      "\n",
      "--2020-09-28 21:21:52--  http://www.cs.umb.edu/~smimarog/textmining/datasets/r8-test-no-stop.txt\n",
      "Resolving www.cs.umb.edu (www.cs.umb.edu)... 158.121.106.224\n",
      "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.cs.umb.edu:443/~smimarog/textmining/datasets/r8-test-no-stop.txt [following]\n",
      "--2020-09-28 21:21:52--  https://www.cs.umb.edu/~smimarog/textmining/datasets/r8-test-no-stop.txt\n",
      "Connecting to www.cs.umb.edu (www.cs.umb.edu)|158.121.106.224|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 904742 (884K) [text/plain]\n",
      "Saving to: ‘r8-test-no-stop.txt.1’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5%  630K 1s\n",
      "    50K .......... .......... .......... .......... .......... 11% 1.33M 1s\n",
      "   100K .......... .......... .......... .......... .......... 16% 12.0M 1s\n",
      "   150K .......... .......... .......... .......... .......... 22% 1.53M 1s\n",
      "   200K .......... .......... .......... .......... .......... 28% 11.9M 0s\n",
      "   250K .......... .......... .......... .......... .......... 33% 5.91M 0s\n",
      "   300K .......... .......... .......... .......... .......... 39%  238M 0s\n",
      "   350K .......... .......... .......... .......... .......... 45% 11.1M 0s\n",
      "   400K .......... .......... .......... .......... .......... 50% 2.08M 0s\n",
      "   450K .......... .......... .......... .......... .......... 56% 11.6M 0s\n",
      "   500K .......... .......... .......... .......... .......... 62% 11.3M 0s\n",
      "   550K .......... .......... .......... .......... .......... 67% 11.7M 0s\n",
      "   600K .......... .......... .......... .......... .......... 73% 11.1M 0s\n",
      "   650K .......... .......... .......... .......... .......... 79% 11.7M 0s\n",
      "   700K .......... .......... .......... .......... .......... 84% 11.8M 0s\n",
      "   750K .......... .......... .......... .......... .......... 90% 11.5M 0s\n",
      "   800K .......... .......... .......... .......... .......... 96% 1.12M 0s\n",
      "   850K .......... .......... .......... ...                  100%  221M=0.3s\n",
      "\n",
      "2020-09-28 21:21:53 (3.25 MB/s) - ‘r8-test-no-stop.txt.1’ saved [904742/904742]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget http://www.cs.umb.edu/~smimarog/textmining/datasets/r8-train-no-stop.txt\n",
    "wget http://www.cs.umb.edu/~smimarog/textmining/datasets/r8-test-no-stop.txt\n",
    "# concatenate train and test files, we'll make our own train-test splits\n",
    "cat r8-*-no-stop.txt > r8-no-stop.txt\n",
    "\n",
    "wget http://www.cs.umb.edu/~smimarog/textmining/datasets/20ng-test-no-stop.txt\n",
    "wget http://www.cs.umb.edu/~smimarog/textmining/datasets/20ng-train-no-stop.txt\n",
    "cat 20ng-*-no-stop.txt > 20ng-no-stop.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train read the data and train word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples 7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "TRAIN_SET_PATH = \"r8-no-stop.txt\"\n",
    "\n",
    "X, y = [], []\n",
    "with open(TRAIN_SET_PATH, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        label, text = line.split(\"\\t\")\n",
    "        # texts are already tokenized, just split on space\n",
    "        # in a real case we would use e.g. spaCy for tokenization\n",
    "        # and maybe remove stopwords etc.\n",
    "        X.append(text.split())\n",
    "        y.append(label)\n",
    "X, y = np.array(X), np.array(y)\n",
    "print (\"total examples %s\" % len(y))\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the main event: we make several different types of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple word counts\n",
    "counts = normalize(CountVectorizer(analyzer=lambda x: x).fit_transform(X), 'l2')\n",
    "\n",
    "# embedding vector averaged over all the words per document\n",
    "mean_vecs = MeanEmbeddingVectorizer(w2v, tfidf=False).fit(X).transform(X)\n",
    "\n",
    "# and a few configutations of EMDE\n",
    "emde_8_10 = normalize(EMDEVectorizer(8, 10, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_8_30 = normalize(EMDEVectorizer(8, 30, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_10_10 = normalize(EMDEVectorizer(10, 10, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_10_30 = normalize(EMDEVectorizer(10, 30, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_1_1000 = normalize(EMDEVectorizer(1, 1000, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_1_2000 = normalize(EMDEVectorizer(1, 2000, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_30_1 = normalize(EMDEVectorizer(30, 1, w2v, tfidf=True).fit(X).transform(X), 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    'OHE': counts,\n",
    "    'mean vec': mean_vecs,\n",
    "    'EMDE K=8 N=10': emde_8_10,\n",
    "    'EMDE K=8 N=30': emde_8_30,\n",
    "    'EMDE K=10 N=10': emde_10_10,\n",
    "    'EMDE K=10 N=30': emde_10_30,\n",
    "    'EMDE K=1  N=1000': emde_1_1000,\n",
    "    'EMDE K=1  N=2000': emde_1_2000,\n",
    "    'EMDE K=30  N=1': emde_30_1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE 22931\n",
      "took 10s\n",
      "0.9528260620293967\n",
      "mean vec 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 3s\n",
      "0.9489178617992178\n",
      "EMDE K=8 N=10 1303\n",
      "took 17s\n",
      "0.9644251260250819\n",
      "EMDE K=8 N=30 4010\n",
      "took 71s\n",
      "0.9675526714769248\n",
      "EMDE K=10 N=10 2554\n",
      "took 20s\n",
      "0.9641637752740276\n",
      "EMDE K=10 N=30 8104\n",
      "took 82s\n",
      "0.9678125783011776\n",
      "EMDE K=1  N=1000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 223s\n",
      "0.9644243615932458\n",
      "EMDE K=1  N=2000 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 441s\n",
      "0.9679433810820107\n",
      "EMDE K=30  N=1 3704\n",
      "took 3s\n",
      "0.958560235105258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "\n",
    "results = {}\n",
    "mean_results = {}\n",
    "for name, feats in feature_sets.items():\n",
    "    print(name, feats.shape[1])\n",
    "    start = time()\n",
    "    scores = cross_val_score(LogisticRegression(max_iter=200), feats, y, cv=5)\n",
    "    end = time()\n",
    "    print('took %ds' % (end - start))\n",
    "    print(scores.mean())\n",
    "    mean_results[name] = scores.mean()\n",
    "    results[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features            accuracy    dim\n",
      "----------------  ----------  -----\n",
      "EMDE K=1  N=2000    0.967943   4000\n",
      "EMDE K=10 N=30      0.967813   8104\n",
      "EMDE K=8 N=30       0.967553   4010\n",
      "EMDE K=8 N=10       0.964425   1303\n",
      "EMDE K=1  N=1000    0.964424   2000\n",
      "EMDE K=10 N=10      0.964164   2554\n",
      "EMDE K=30  N=1      0.95856    3704\n",
      "OHE                 0.952826  22931\n",
      "mean vec            0.948918    100\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "final_results = sorted([\n",
    "    (name, acc, feature_sets[name].shape[1])\n",
    "    for name, acc in mean_results.items()\n",
    "], key=lambda x: -x[1])\n",
    "\n",
    "print(tabulate(final_results, headers=['features', 'accuracy', 'dim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples 18821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "TEXTS_PATH = \"20ng-no-stop.txt\"\n",
    "\n",
    "X, y = [], []\n",
    "with open(TEXTS_PATH, \"r\") as infile:\n",
    "    for line in infile:\n",
    "        label, text = line.split(\"\\t\")\n",
    "        # texts are already tokenized, just split on space\n",
    "        # in a real case we would use e.g. spaCy for tokenization\n",
    "        # and maybe remove stopwords etc.\n",
    "        X.append(text.split())\n",
    "        y.append(label)\n",
    "X, y = np.array(X), np.array(y)\n",
    "print (\"total examples %s\" % len(y))\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple word counts\n",
    "counts = normalize(CountVectorizer(analyzer=lambda x: x).fit_transform(X), 'l2')\n",
    "\n",
    "# embedding vector averaged over all the words per document\n",
    "mean_vecs = MeanEmbeddingVectorizer(w2v, tfidf=False).fit(X).transform(X)\n",
    "\n",
    "# and a few configutations of EMDE\n",
    "emde_8_10 = normalize(EMDEVectorizer(8, 10, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_8_30 = normalize(EMDEVectorizer(8, 30, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_10_10 = normalize(EMDEVectorizer(10, 10, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_10_30 = normalize(EMDEVectorizer(10, 30, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_1_1000 = normalize(EMDEVectorizer(1, 1000, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_1_2000 = normalize(EMDEVectorizer(1, 2000, w2v, tfidf=False).fit(X).transform(X), 'max')\n",
    "emde_30_1 = normalize(EMDEVectorizer(30, 1, w2v, tfidf=True).fit(X).transform(X), 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    'OHE': counts,\n",
    "    'mean vec': mean_vecs,\n",
    "    'EMDE K=8 N=10': emde_8_10,\n",
    "    'EMDE K=8 N=30': emde_8_30,\n",
    "    'EMDE K=10 N=10': emde_10_10,\n",
    "    'EMDE K=10 N=30': emde_10_30,\n",
    "    'EMDE K=1  N=1000': emde_1_1000,\n",
    "    'EMDE K=1  N=2000': emde_1_2000,\n",
    "    'EMDE K=30  N=1': emde_30_1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE 92811\n",
      "took 197s\n",
      "0.8258328499674696\n",
      "mean vec 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 15s\n",
      "0.6195209244495627\n",
      "EMDE K=8 N=10 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 169s\n",
      "0.7819983685520053\n",
      "EMDE K=8 N=30 5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 479s\n",
      "0.8178092165521406\n",
      "EMDE K=10 N=10 5191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 224s\n",
      "0.809945397298514\n",
      "EMDE K=10 N=30 15855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 816s\n",
      "0.8374683765822294\n",
      "EMDE K=1  N=1000 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 690s\n",
      "0.7537326993831265\n",
      "EMDE K=1  N=2000 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/nadbordrozd/anaconda3/envs/elections/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 1359s\n",
      "0.764093410276711\n",
      "EMDE K=30  N=1 20694\n",
      "took 49s\n",
      "0.872641859060393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "\n",
    "results = {}\n",
    "mean_results = {}\n",
    "for name, feats in feature_sets.items():\n",
    "    print(name, feats.shape[1])\n",
    "    start = time()\n",
    "    scores = cross_val_score(LogisticRegression(max_iter=200), feats, y, cv=5)\n",
    "    end = time()\n",
    "    print('took %ds' % (end - start))\n",
    "    print(scores.mean())\n",
    "    mean_results[name] = scores.mean()\n",
    "    results[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features            accuracy    dim\n",
      "----------------  ----------  -----\n",
      "EMDE K=30  N=1      0.872642  20694\n",
      "EMDE K=10 N=30      0.837468  15855\n",
      "OHE                 0.825833  92811\n",
      "EMDE K=8 N=30       0.817809   5850\n",
      "EMDE K=10 N=10      0.809945   5191\n",
      "EMDE K=8 N=10       0.781998   2048\n",
      "EMDE K=1  N=2000    0.764093   4000\n",
      "EMDE K=1  N=1000    0.753733   2000\n",
      "mean vec            0.619521    100\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "final_results = sorted([\n",
    "    (name, acc, feature_sets[name].shape[1])\n",
    "    for name, acc in mean_results.items()\n",
    "], key=lambda x: -x[1])\n",
    "\n",
    "print(tabulate(final_results, headers=['features', 'accuracy', 'dim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More general implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class Bucketizer(object):\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "        self.d = None\n",
    "        self.n_vectors = None\n",
    "        self.thresholds = None\n",
    "        self.random_vectors = None\n",
    "\n",
    "    def fit(self, vectors, y=None):\n",
    "        self.n_vectors, self.d = vectors.shape\n",
    "        self.random_vectors = np.random.normal(size=(self.K, self.d))\n",
    "        scalar_products = self.random_vectors.dot(vectors.T)\n",
    "        \n",
    "        random_inds = np.random.randint(self.n_vectors, size=self.K)\n",
    "        self.thresholds = scalar_products[range(self.K), random_inds]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, vectors):\n",
    "        n_vectors, dim = vectors.shape\n",
    "        scalar_products = self.random_vectors.dot(vectors.T)\n",
    "        bits = (scalar_products > self.thresholds.reshape([self.K, 1])).T.astype('uint8')\n",
    "        bucket_nums = (bits * (2**np.arange(self.K))).sum(axis=1).astype('uint16')\n",
    "        return bucket_nums.reshape((n_vectors, 1))\n",
    "\n",
    "\n",
    "class EMDE(object):\n",
    "    \"\"\"This version of EMDE vectorizer can aggregate never before seen vectors\n",
    "    It also doesn't drop any buckets, even if none of the training vectors fell into the bucket\n",
    "    \"\"\"\n",
    "    def __init__(self, K, N):\n",
    "        vectorizer = CountVectorizer(analyzer=lambda x: x, \n",
    "                                     vocabulary=[i for i in range(2**K)])\n",
    "\n",
    "        self.bucketizers = [\n",
    "            Pipeline([('bucketizer', Bucketizer(K)), \n",
    "                      (\"OHE\", vectorizer)])\n",
    "            for _ in range(N)\n",
    "        ]\n",
    "        self.vector_encodings = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"fits the model given an array of vectors\n",
    "        \"\"\"\n",
    "        for b in self.bucketizers:\n",
    "            b.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform_vectors(self, vectors):\n",
    "        \"\"\"takes an array of vectors and transforms them individually returning array of sketches\"\"\"\n",
    "        sketches = np.hstack([b.transform(vectors).todense() \n",
    "                              for b in self.bucketizers])\n",
    "        return sketches\n",
    "\n",
    "\n",
    "    def transform_vector_set(self, vectors):\n",
    "        \"\"\"takes an array of vectors and returns a single sketch representing all of them\"\"\"\n",
    "        return self.transform_vectors(vectors).sum(axis=0)\n",
    "\n",
    "\n",
    "training_vectors = np.array([\n",
    "    [-0.1, 0.4, 0.7, 0.3],\n",
    "    [0.4, 0.12, 0.6, 0.1],\n",
    "    [0.8, 0.3, 0.5, -0.5],\n",
    "    [0.1, 0.5, 0.23, 0.6]\n",
    "])\n",
    "\n",
    "vectors_to_agg = np.array([\n",
    "    [0.76, 0.8, -0.6, 0.1],\n",
    "    [0.23, 0.3, 0.51, -0.5]\n",
    "])\n",
    "\n",
    "\n",
    "emde = EMDE(K=3, N=2)\n",
    "emde.fit(training_vectors)\n",
    "sketch = emde.transform_vector_set(vectors_to_agg)\n",
    "sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
